{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b4a4b25c",
   "metadata": {},
   "source": [
    "# SAM Postprocessing for DFU2024 Challenge"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07fabfee",
   "metadata": {},
   "source": [
    "If running locally using jupyter, first install `segment-anything-2` in your environment using the [installation instructions](https://github.com/facebookresearch/segment-anything-2#installation) in the repository."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0be845da",
   "metadata": {},
   "source": [
    "## Set-up"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33681dd1",
   "metadata": {},
   "source": [
    "Necessary imports and helper functions for displaying points, boxes, and masks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "69b28288",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "from sam2.build_sam import build_sam2\n",
    "from sam2.sam2_image_predictor import SAM2ImagePredictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "33a15e2f-c7e1-4e5d-862f-fcb751a60b89",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# use bfloat16 for the entire notebook\n",
    "torch.autocast(device_type=\"cuda\", dtype=torch.bfloat16).__enter__()\n",
    "\n",
    "if torch.cuda.get_device_properties(0).major >= 8:\n",
    "    # turn on tfloat32 for Ampere GPUs (https://pytorch.org/docs/stable/notes/cuda.html#tensorfloat-32-tf32-on-ampere-devices)\n",
    "    torch.backends.cuda.matmul.allow_tf32 = True\n",
    "    torch.backends.cudnn.allow_tf32 = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23842fb2",
   "metadata": {},
   "source": [
    "## Data preparation for bounding box provided by skimage.region props saved in .csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48d8cc12-1e6d-4025-a6c1-c05fdc6fe9b8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Custom converter for the tuple\n",
    "def tuple_converter(s):\n",
    "    # Convert the bytes to a string and strip the parentheses\n",
    "    s = s.decode(\"utf-8\").strip('\"()\"')\n",
    "    # Split by commas and convert to integers\n",
    "    split_values = s.split(',')\n",
    "    # Reorder the columns: 2nd, 1st, 4th, 3rd to match SAM2 format\n",
    "    reordered_values = [split_values[1], split_values[0], split_values[3], split_values[2]]\n",
    "    # Convert the reordered list to integers and then to a numpy array\n",
    "    return np.array(list(map(int, reordered_values)))\n",
    "    \n",
    "# Load the data\n",
    "data_bbox = np.genfromtxt(\n",
    "    '.../DFU/bbox_coords_test.csv', \n",
    "    delimiter=';', \n",
    "    skip_header=1,\n",
    "    dtype=[('filename', 'U50'), ('values', 'O')],  # U50: max 50 char string, O: object\n",
    "    converters={1: tuple_converter}  # Apply the tuple converter to the second column\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a15f373e-abbf-4c21-8d55-c31def9f3a2d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Merging all of the bounding boxes for each of the image files to match SAM2 format\n",
    "import numpy as np\n",
    "\n",
    "def merge_values_by_filename(data):\n",
    "    # Initialize a dictionary to hold the merged values\n",
    "    merged_dict = {}\n",
    "    # Iterate over the data to merge arrays by filename\n",
    "    for item in data:\n",
    "        filename = item['filename']\n",
    "        values = item['values']      \n",
    "        if filename in merged_dict:\n",
    "            merged_dict[filename].append(values)\n",
    "        else:\n",
    "            merged_dict[filename] = [values]\n",
    "    # Convert the dictionary back to a structured numpy array\n",
    "    merged_data = np.array([(filename, np.array(values)) for filename, values in merged_dict.items()],\n",
    "                           dtype=[('filename', 'U50'), ('values', 'O')])\n",
    "    return merged_data\n",
    "\n",
    "bbox_merged = merge_values_by_filename(data_bbox)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98b228b8",
   "metadata": {},
   "source": [
    "## Selecting objects with SAM 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bb1927b",
   "metadata": {},
   "source": [
    "First, load the SAM 2 model and predictor. Change the path below to point to the SAM 2 checkpoint. Running on CUDA and using the default model are recommended for best results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7e28150b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sam2_checkpoint = \"../segment-anything-2/checkpoints/sam2_hiera_large.pt\"\n",
    "model_cfg = \"sam2_hiera_l.yaml\"\n",
    "\n",
    "sam2_model = build_sam2(model_cfg, sam2_checkpoint, device=\"cuda\")\n",
    "\n",
    "predictor = SAM2ImagePredictor(sam2_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82c2db5d-d45d-451d-a94d-b4c7303a0bcb",
   "metadata": {},
   "source": [
    "## Loop for masks generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "01a2af8e-b8bc-4296-8feb-28917671b0cd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "output_folder = \"test-set\"\n",
    "dateset_folder_name = '../DFU/DFUC2024_test_release/'\n",
    "\n",
    "if not os.path.exists(output_folder):\n",
    "    os.makedirs(output_folder)\n",
    "\n",
    "for entry in bbox_merged:\n",
    "    # Open the image\n",
    "    with Image.open(dateset_folder_name+entry['filename']) as img:\n",
    "        image = np.array(img.convert(\"RGB\"))\n",
    "    \n",
    "    # Process the bounding boxes\n",
    "    input_boxes = np.array(entry['values'])\n",
    "    predictor.set_image(image)\n",
    "    masks, scores, _ = predictor.predict(\n",
    "        point_coords=None,\n",
    "        point_labels=None,\n",
    "        box=input_boxes,\n",
    "        multimask_output=False,\n",
    "    )\n",
    "    \n",
    "    if len(masks.shape) == 4:\n",
    "        merged_mask = np.any(masks.squeeze(1), axis=0)\n",
    "    else:\n",
    "        merged_mask = masks.squeeze(0)\n",
    "    merged_mask_image = (merged_mask * 255).astype(np.uint8)\n",
    "    merged_mask_pil = Image.fromarray(merged_mask_image)\n",
    "    merged_mask_pil.save(output_folder+\"/\"+entry['filename'].split('.')[0]+\".png\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
